{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the data from the Internet and save it as csv\n",
    "The following cell only needs to run once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# # fetch dataset \n",
    "# breast_cancer_wisconsin_original = fetch_ucirepo(id=15) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = breast_cancer_wisconsin_original.data.features \n",
    "# y = breast_cancer_wisconsin_original.data.targets \n",
    "\n",
    "# data = pd.concat([y, X], axis=1)\n",
    "# data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data to X and y, and replace B and M (2&4) with 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are missing values. As we got a large dataset, we will just drop the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 9) (683,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.dropna(inplace=True)\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data['Class']\n",
    "y.replace({2: 0, 4: 1}, inplace=True)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)\n",
    "b=np.array([4,5,6]).reshape(1, -1)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.dot(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: input size: 5, output size: 3\n",
      "Layer 2: input size: 3, output size: 2\n",
      "Layer 3: input size: 2, output size: 1\n",
      "75\n",
      "[-5.51171724  3.7885127   3.51284415]\n",
      "[1.8843869  3.58148066]\n",
      "[-0.84304831]\n",
      "\n",
      "[-5.20376347  3.76446961  3.15433602]\n",
      "[1.68804385 2.91174327]\n",
      "[-0.23492703]\n",
      "\n",
      "[-5.0784975   3.75476497  2.99209297]\n",
      "[1.65542194 2.60864505]\n",
      "[0.14507756]\n",
      "\n",
      "[-5.08024055  3.74101878  2.97459164]\n",
      "[1.74572682 2.54761618]\n",
      "[0.46832078]\n",
      "\n",
      "[-5.1925814   3.71979515  3.08439853]\n",
      "[1.9554449 2.6915306]\n",
      "[0.83364981]\n",
      "\n",
      "[-5.42229981  3.69685619  3.32363778]\n",
      "[2.30669991 3.05136438]\n",
      "[1.34045535]\n",
      "\n",
      "[-5.79698575  3.68667933  3.71129963]\n",
      "[2.85367578 3.68534452]\n",
      "[2.14143637]\n",
      "\n",
      "[-6.36998643  3.71501747  4.28656277]\n",
      "[3.70593307 4.72386686]\n",
      "[3.53112536]\n",
      "\n",
      "[-7.23208118  3.82439827  5.11738746]\n",
      "[5.08141931 6.43260795]\n",
      "[6.15359783]\n",
      "\n",
      "[-8.52810884  4.08215927  6.31268102]\n",
      "[7.41625582 9.34576746]\n",
      "[11.53488423]\n",
      "\n",
      "[-10.45354777   4.58226916   8.01726958]\n",
      "[11.53419342 14.47223834]\n",
      "[23.33581058]\n",
      "\n",
      "[-13.06908911   5.38106613  10.25766435]\n",
      "[18.41389218 23.00701526]\n",
      "[48.23431959]\n",
      "\n",
      "[-15.32641527   6.1352386   12.14942169]\n",
      "[25.54582847 31.84255969]\n",
      "[79.56238769]\n",
      "\n",
      "[-14.78326586   5.94724992  11.69851566]\n",
      "[23.73362837 29.59406099]\n",
      "[71.13403245]\n",
      "\n",
      "[-15.20956175   6.09390835  12.0529967 ]\n",
      "[25.15199354 31.35277887]\n",
      "[77.70674672]\n",
      "\n",
      "[-14.89247125   5.98427916  11.78968013]\n",
      "[24.09403452 30.04032601]\n",
      "[72.78736157]\n",
      "\n",
      "[-15.14033333   6.06967106  11.99570762]\n",
      "[24.91964304 31.06415664]\n",
      "[76.61808974]\n",
      "\n",
      "[-14.95259518   6.00480878  11.83977736]\n",
      "[24.29336158 30.28729205]\n",
      "[73.70675654]\n",
      "\n",
      "[-15.09871751   6.05518698  11.9612125 ]\n",
      "[24.78032586 30.89121037]\n",
      "[75.96753232]\n",
      "\n",
      "[-14.98711253   6.01664517  11.86850524]\n",
      "[24.40807533 30.4294797 ]\n",
      "[74.23746485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    num_of_layers = 0\n",
    "    def __init__(self, input_size, output_size, activation=\"linear\"):\n",
    "        self.weights = random.rand(input_size+1, output_size)-0.5   # weight[0, x] is bias's weight\n",
    "        # self.weights[:,:] = 1\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        if activation == \"linear\":\n",
    "            self.activation_function = lambda x: x\n",
    "            self.d_activation_function = lambda x: 1\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation_function = lambda x: 1/(1+np.exp(-x))\n",
    "            # self.d_activation_function = lambda x: \n",
    "        else:\n",
    "            raise Exception(\"Wrong activation function\")\n",
    "        Layer.num_of_layers += 1\n",
    "\n",
    "    def forward_propagation(self, input):   # input should be an array\n",
    "        input = np.concatenate(([[1], input]))    # add bias = 1\n",
    "        self.input = input\n",
    "        output = self.activation_function(input.dot(self.weights))\n",
    "        self.output = output\n",
    "        return output\n",
    "    \n",
    "    def backward_propagation(self, dl_dy, learning_rate = 0.0002):\n",
    "        if self.activation == \"linear\":\n",
    "            d_da = 1\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            pass\n",
    "        # print(f\"dl_dy.shape: {dl_dy.shape}\")\n",
    "        # print(f\"self.weights.shape: {self.weights.shape}\")\n",
    "\n",
    "        da_dw = self.input.reshape(-1, 1)\n",
    "        # print(f\"da_dw.shape: {da_dw.shape}\")\n",
    "\n",
    "        dl_dw = da_dw.dot(dl_dy.T * d_da)\n",
    "        # print(f\"dl_dw.shape: {dl_dw.shape}\")\n",
    "\n",
    "        dl_dx = (self.weights[1:]).dot(dl_dy * d_da)\n",
    "        # print(f\"dl_dx.shape: {dl_dx.shape}\")\n",
    "\n",
    "        self.weights -= learning_rate * dl_dw\n",
    "\n",
    "        # print()\n",
    "        return dl_dx\n",
    "        \n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def show_layers(self):\n",
    "        for i, l in enumerate(self.layers):\n",
    "            print(f\"Layer {i+1}: \", end=\"\")\n",
    "            print(f\"input size: {l.input_size}, output size: {l.output_size}\")\n",
    "\n",
    "    def fp1(self, input):\n",
    "        prev_output = input\n",
    "        for layer in self.layers:\n",
    "            prev_output = layer.forward_propagation(prev_output)\n",
    "            print(prev_output)\n",
    "        return prev_output\n",
    "\n",
    "    def one_cycle(self, input, expected_output):\n",
    "        pred = self.fp1(input)\n",
    "        error = (expected_output - pred)\n",
    "        sq_error = (expected_output - pred)**2\n",
    "        derror_dpred = -2 * error\n",
    "        derror_dpred = np.array(derror_dpred).reshape(1, 1)\n",
    "        dl_dy = derror_dpred\n",
    "        for layer in reversed(self.layers):\n",
    "            dl_dy = layer.backward_propagation(dl_dy)\n",
    "\n",
    "        print()\n",
    "    \n",
    "layer1 = Layer(5, 3, activation=\"linear\")\n",
    "layer2 = Layer(3, 2, activation=\"linear\")\n",
    "layer3 = Layer(2, 1, activation=\"linear\")\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.add(layer1)\n",
    "model.add(layer2)\n",
    "model.add(layer3)\n",
    "model.show_layers()\n",
    "\n",
    "input = np.array([5, 8, 3, 2, 1])\n",
    "expected_output = sum(input*[3, 4, 6, 2, 1])+5\n",
    "print(expected_output)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    model.one_cycle(input, expected_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLiSTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
