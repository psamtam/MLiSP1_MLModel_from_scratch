{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the data from the Internet and save it as csv\n",
    "The following cell only needs to run once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# # fetch dataset \n",
    "# breast_cancer_wisconsin_original = fetch_ucirepo(id=15) \n",
    "  \n",
    "# # data (as pandas dataframes) \n",
    "# X = breast_cancer_wisconsin_original.data.features \n",
    "# y = breast_cancer_wisconsin_original.data.targets \n",
    "\n",
    "# data = pd.concat([y, X], axis=1)\n",
    "# data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data to X and y, and replace B and M (2&4) with 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are missing values. As we got a large dataset, we will just drop the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(683, 9) (683,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.dropna(inplace=True)\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data['Class']\n",
    "y.replace({2: 0, 4: 1}, inplace=True)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3]).reshape(-1,1)\n",
    "b=np.array([4,5,6]).reshape(1, -1)\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "print(a.dot(b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: input size: 5, output size: 3\n",
      "Layer 2: input size: 3, output size: 2\n",
      "Layer 3: input size: 2, output size: 1\n",
      "75\n",
      "[0.90383077 0.66150987 0.02232874]\n",
      "[0.42972556 0.40456384]\n",
      "[-0.01360161]\n",
      "\n",
      "[0.41108853 0.1267539  0.00169344]\n",
      "[0.49191418 0.43256531]\n",
      "[20.81612625]\n",
      "\n",
      "[0.04929096 0.01066601 0.00012598]\n",
      "[0.53215649 0.46115369]\n",
      "[37.10903501]\n",
      "\n",
      "[3.83605527e-03 8.00102725e-04 9.35772810e-06]\n",
      "[0.53711178 0.46488875]\n",
      "[48.57961996]\n",
      "\n",
      "[2.85932938e-04 5.94705407e-05 6.95037971e-07]\n",
      "[0.53749799 0.4651814 ]\n",
      "[56.54243453]\n",
      "\n",
      "[2.12428854e-05 4.41733305e-06 5.16229903e-08]\n",
      "[0.53752678 0.46520322]\n",
      "[62.10027563]\n",
      "\n",
      "[1.57781614e-06 3.28092473e-07 3.83422439e-09]\n",
      "[0.53752892 0.46520484]\n",
      "[65.98407354]\n",
      "\n",
      "[1.17190221e-07 2.43686094e-08 2.84781566e-10]\n",
      "[0.53752908 0.46520496]\n",
      "[68.69850994]\n",
      "\n",
      "[8.70413801e-09 1.80994386e-09 2.11517459e-11]\n",
      "[0.53752909 0.46520497]\n",
      "[70.59570402]\n",
      "\n",
      "[6.46487481e-10 1.34431007e-10 1.57101586e-12]\n",
      "[0.53752909 0.46520497]\n",
      "[71.92170826]\n",
      "\n",
      "[4.80169385e-11 9.98467190e-12 1.16684969e-13]\n",
      "[0.53752909 0.46520497]\n",
      "[72.84849152]\n",
      "\n",
      "[3.56638984e-12 7.41597309e-13 8.66661018e-15]\n",
      "[0.53752909 0.46520497]\n",
      "[73.49624755]\n",
      "\n",
      "[2.64888534e-13 5.50810857e-14 6.43700149e-16]\n",
      "[0.53752909 0.46520497]\n",
      "[73.94898326]\n",
      "\n",
      "[1.96742193e-14 4.09106933e-15 4.78099134e-17]\n",
      "[0.53752909 0.46520497]\n",
      "[74.26541354]\n",
      "\n",
      "[1.46127466e-15 3.03858358e-16 3.55101334e-18]\n",
      "[0.53752909 0.46520497]\n",
      "[74.48657595]\n",
      "\n",
      "[1.08534098e-16 2.25686475e-17 2.63746467e-19]\n",
      "[0.53752909 0.46520497]\n",
      "[74.64115286]\n",
      "\n",
      "[8.06121582e-18 1.67625421e-18 1.95893939e-20]\n",
      "[0.53752909 0.46520497]\n",
      "[74.74919114]\n",
      "\n",
      "[5.98735344e-19 1.24501398e-19 1.45497438e-21]\n",
      "[0.53752902 0.46520471]\n",
      "[74.82469444]\n",
      "\n",
      "[4.44702173e-20 9.24716431e-21 1.08066153e-22]\n",
      "[0.53752569 0.46519646]\n",
      "[74.87720065]\n",
      "\n",
      "[3.30297150e-21 6.86820006e-22 8.02646036e-24]\n",
      "[0.537478  0.4651066]\n",
      "[74.91090092]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psamt\\AppData\\Local\\Temp\\ipykernel_41104\\2113517622.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.activation_function = lambda x: 1/(1+np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    num_of_layers = 0\n",
    "    def __init__(self, input_size, output_size, activation=\"linear\"):\n",
    "        self.weights = random.rand(input_size+1, output_size)-0.5   # weight[0, x] is bias's weight\n",
    "        # self.weights[:,:] = 0.6\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        if activation == \"linear\":\n",
    "            self.activation_function = lambda x: x\n",
    "            self.d_activation_function = lambda x: x * 1\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation_function = lambda x: 1/(1+np.exp(-x))\n",
    "            self.d_activation_function = lambda x: self.activation_function(x) * (1 - self.activation_function(x))\n",
    "        else:\n",
    "            raise Exception(\"Wrong activation function\")\n",
    "        Layer.num_of_layers += 1\n",
    "\n",
    "    def forward_propagation(self, input):   # input should be an array\n",
    "        input = np.concatenate(([[1], input]))    # add bias = 1\n",
    "        self.input = input\n",
    "        output = self.activation_function(input.dot(self.weights))\n",
    "        self.output = output\n",
    "        return output\n",
    "    \n",
    "    def backward_propagation(self, dl_dy, learning_rate = 0.1):\n",
    "        # print(f\"dl_dy.shape: {dl_dy.shape}\")\n",
    "        # print(f\"self.weights.shape: {self.weights.shape}\")\n",
    "\n",
    "        da_dw = self.input.reshape(-1, 1)\n",
    "        # print(f\"da_dw.shape: {da_dw.shape}\")\n",
    "\n",
    "        dl_dw = da_dw.dot(self.d_activation_function(dl_dy.T))\n",
    "        # print(f\"dl_dw.shape: {dl_dw.shape}\")\n",
    "\n",
    "        dl_dx = (self.weights[1:]).dot(self.d_activation_function(dl_dy))\n",
    "        # print(f\"dl_dx.shape: {dl_dx.shape}\")\n",
    "\n",
    "        self.weights -= learning_rate * dl_dw\n",
    "\n",
    "        # print()\n",
    "        return dl_dx\n",
    "        \n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def show_layers(self):\n",
    "        for i, l in enumerate(self.layers):\n",
    "            print(f\"Layer {i+1}: \", end=\"\")\n",
    "            print(f\"input size: {l.input_size}, output size: {l.output_size}\")\n",
    "\n",
    "    def predict(self, input):\n",
    "        prev_output = input\n",
    "        for layer in self.layers:\n",
    "            prev_output = layer.forward_propagation(prev_output)\n",
    "            print(prev_output)\n",
    "        return prev_output\n",
    "\n",
    "    def one_cycle(self, input, expected_output):\n",
    "        pred = self.predict(input)\n",
    "        error = (expected_output - pred)\n",
    "        sq_error = (expected_output - pred)**2\n",
    "        # d(squared error)/d(prediction)\n",
    "        derror_dpred = -2 * error\n",
    "        derror_dpred = np.array([derror_dpred])\n",
    "        dl_dy = derror_dpred\n",
    "        for layer in reversed(self.layers):\n",
    "            dl_dy = layer.backward_propagation(dl_dy)\n",
    "\n",
    "        print()\n",
    "    \n",
    "layer1 = Layer(5, 3, activation=\"sigmoid\")\n",
    "layer2 = Layer(3, 2, activation=\"sigmoid\")\n",
    "layer3 = Layer(2, 1, activation=\"linear\")\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.add(layer1)\n",
    "model.add(layer2)\n",
    "model.add(layer3)\n",
    "model.show_layers()\n",
    "\n",
    "input = np.array([5, 8, 3, 2, 1])\n",
    "expected_output = sum(input*[3, 4, 6, 2, 1])+5\n",
    "print(expected_output)\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    model.one_cycle(input, expected_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLiSTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
